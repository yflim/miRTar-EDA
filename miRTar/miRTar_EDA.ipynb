{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# miRNA-target relationships in cancer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import datetime\n",
    "import datalab.bigquery as bq\n",
    "import google.datalab.storage as storage\n",
    "import io\n",
    "import logging\n",
    "import math as m\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.stats as stats\n",
    "import seaborn as sns\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_file(bucket, filepath, **kwargs):\n",
    "  uri = bucket.object(filepath).uri\n",
    "  get_ipython().run_line_magic('gcs', 'read --object ' + uri + ' --variable csv_data')\n",
    "  return pd.read_csv(io.BytesIO(csv_data), **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_df_to_csv(df, index_label, csv_filepath):\n",
    "  df.to_csv('temp.csv', index_label = index_label)\n",
    "  !gsutil cp 'temp.csv' $csv_filepath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_series_to_csv(series, index_label, csv_filepath):\n",
    "  series.to_csv('temp.csv', index_label = index_label)\n",
    "  !gsutil cp 'temp.csv' $csv_filepath"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = logging.getLogger()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_file_logger(log_file):\n",
    "    for handler in logger.handlers[:]:\n",
    "        logger.removeHandler(handler)\n",
    "    hdlr = logging.FileHandler(log_file)\n",
    "    formatter = logging.Formatter('%(asctime)s %(levelname)s %(message)s')\n",
    "    hdlr.setFormatter(formatter)\n",
    "    logger.addHandler(hdlr) \n",
    "    logger.setLevel(logging.INFO)\n",
    "    \n",
    "def log(message):\n",
    "  print(message)\n",
    "  logger.info(message)\n",
    "\n",
    "setup_file_logger('mirtar.log')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "bucket = storage.Bucket('yfl-mirna')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### miRTar data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read miRTar data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "mirtar_data = read_file(bucket, 'data/miRTar/miRTarBase_MTI.csv', encoding='ISO-8859-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "colnames_from_to = { 'miRTarBase ID': 'mirtarbaseID', 'Species (miRNA)': 'miRNA_species', 'Target Gene': 'targetID',\n",
    "                     'Target Gene (Entrez ID)': 'target_entrezID', 'Species (Target Gene)': 'target_species',\n",
    "                     'Support Type': 'support_type', 'References (PMID)': 'PMID_references' }\n",
    "mirtar_data.rename(columns=colnames_from_to, inplace=True)\n",
    "mirtar_data.set_index('miRNA', inplace=True)\n",
    "mirtar_data = mirtar_data[mirtar_data.target_species == 'Homo sapiens']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mirtar_data['targetID'].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mirtar_data['target_entrezID'].isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Optional, good to know: Identify any inconsistent target IDs in miRTarBase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mirtarbase_target_ID_to_entrezIDs = {}\n",
    "mirtarbase_target_entrezID_to_IDs = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for miRNA, row in mirtar_data.iterrows():\n",
    "    if row['targetID'] in mirtarbase_target_ID_to_entrezIDs:\n",
    "        mirtarbase_target_ID_to_entrezIDs[row['targetID']].add(row['target_entrezID'])\n",
    "    else:\n",
    "        mirtarbase_target_ID_to_entrezIDs[row['targetID']] = { row['target_entrezID'] }\n",
    "    if row['target_entrezID'] in mirtarbase_target_entrezID_to_IDs:\n",
    "        mirtarbase_target_entrezID_to_IDs[row['target_entrezID']].add(row['targetID'])\n",
    "    else:\n",
    "        mirtarbase_target_entrezID_to_IDs[row['target_entrezID']] = { row['targetID'] }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "{ targetID: entrezID for targetID, entrezID in mirtarbase_target_ID_to_entrezIDs.items() if len(entrezID) > 1 }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "{ entrezID: targetID for entrezID, targetID in mirtarbase_target_entrezID_to_IDs.items() if len(targetID) > 1 }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### mRNA data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read sample mRNA expression data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "mRNA_data = read_file(bucket, 'data/mRNA/EBPlusPlusAdjustPANCAN_IlluminaHiSeq_RNASeqV2.geneExp.tsv', delimiter='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "mRNA_data.rename(index=str, columns={'gene_id': 'mRNA'}, inplace=True)\n",
    "mRNA_data.set_index('mRNA', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "mRNA_ID_pairs = mRNA_data.index.map(lambda x: x.split('|'))\n",
    "mRNA_IDs = mRNA_ID_pairs.map(lambda x: x[0])\n",
    "mRNA_entrezIDs = mRNA_ID_pairs.map(lambda x: int(x[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "mRNA_entrezID_to_IDs = pd.DataFrame(index=mRNA_ID_pairs.map(lambda x: int(x[1])))\n",
    "mRNA_entrezID_to_IDs['mRNA_data_ID'] = mRNA_data.index\n",
    "mRNA_entrezID_to_IDs['ID'] = mRNA_IDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "mRNA_ID_to_IDs = pd.DataFrame(index=mRNA_ID_pairs.map(lambda x: x[0]))\n",
    "mRNA_ID_to_IDs['mRNA_data_ID'] = mRNA_data.index\n",
    "mRNA_ID_to_IDs['entrezID'] = mRNA_entrezIDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "mRNA_data['entrezID'] = mRNA_entrezIDs\n",
    "mRNA_data.set_index('entrezID', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Transpose mRNA_data to get samples as rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_mRNAs = mRNA_data.T\n",
    "sample_mRNAs.index = sample_mRNAs.index.map(lambda x: '-'.join(x.split('-')[0:4]))\n",
    "sample_mRNAs.reset_index(inplace=True)\n",
    "sample_mRNAs.drop_duplicates(subset='index', keep='first', inplace=True)\n",
    "sample_mRNAs.set_index('index', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Optional, good to know: Check for mRNAs with ambiguous IDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def add_to_dict(d, key, val):\n",
    "    if key in d:\n",
    "        d[key].add(val)\n",
    "    else:\n",
    "        d[key] = { val } "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ambiguous_mRNAs = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tars_not_in_data = set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for miRNA, row in mirtar_data.iterrows():\n",
    "    mRNA_data_entrezIDs = mRNA_entrezID_to_IDs.index.values\n",
    "    mRNA_data_IDs = mRNA_ID_to_IDs.index.values\n",
    "    row_IDs = row['targetID'] + '|' + str(row['target_entrezID'])\n",
    "    if row['target_entrezID'] in mRNA_data_entrezIDs:\n",
    "        mRNA_entrezID_to_IDs_entry = mRNA_entrezID_to_IDs.loc[row['target_entrezID']]\n",
    "        if row['targetID'] != mRNA_entrezID_to_IDs_entry.ID:\n",
    "            add_to_dict(ambiguous_mRNAs, mRNA_entrezID_to_IDs_entry.mRNA_data_ID, row_IDs)\n",
    "    elif row['targetID'] in mRNA_data_IDs:\n",
    "        mRNA_ID_to_IDs_entry = mRNA_ID_to_IDs.loc[row['targetID']]\n",
    "        if row['target_entrezID'] != mRNA_ID_to_IDs_entry.entrezID:\n",
    "            add_to_dict(ambiguous_mRNAs, mRNA_ID_to_IDs_entry.mRNA_data_ID, row_IDs)\n",
    "    else:\n",
    "        tars_not_in_data.add(row['target_entrezID'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(tars_not_in_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(ambiguous_mRNAs.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(ambiguous_mRNAs.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### miRNA data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read sample miRNA expression data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "miRNA_data = read_file(bucket, 'data/miRNA/pancanMiRs_EBadjOnProtocolPlatformWithoutRepsWithUnCorrectMiRs_08_04_16.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "miRNA_data.rename(index=str, columns={'Genes': 'miRNA'}, inplace=True)\n",
    "miRNA_data.set_index('miRNA', inplace=True)\n",
    "miRNA_data['Corrected'] = (miRNA_data['Correction'] == 'Corrected')\n",
    "del miRNA_data['Correction']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "miRNA_corrections = pd.DataFrame(miRNA_data[['Corrected']])\n",
    "del miRNA_data['Corrected']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "miRNA_data.index.unique().size == miRNA_data.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Transpose miRNA_data to get samples as rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_miRNAs = miRNA_data.T\n",
    "sample_miRNAs.index = sample_miRNAs.index.map(lambda x: '-'.join(x.split('-')[0:4]))\n",
    "sample_miRNAs.reset_index(inplace=True)\n",
    "sample_miRNAs.drop_duplicates(subset='index', keep='first', inplace=True)\n",
    "sample_miRNAs.set_index('index', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "miRNAs_num = len(sample_miRNAs.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute number of targets for miRNAs and write to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "miRNA_target_counts = mirtar_data.groupby('miRNA').size()\n",
    "miRNA_target_counts = miRNA_target_counts.loc[miRNA_data.index.intersection(miRNA_target_counts.index)]\n",
    "write_series_to_csv(miRNA_target_counts, miRNA_target_counts.index, 'gs://yfl-mirna/data/miRTar/miRNA-target-counts.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "miRNA_target_counts = read_file(bucket, 'data/miRTar/miRNA-target-counts.csv', header=None)\n",
    "miRNA_target_counts.rename(columns = { 0: 'miRNA', 1: 'targets_count' }, inplace=True)\n",
    "miRNA_target_counts.set_index('miRNA', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sample metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_metadata = read_file(bucket, 'data/sample/PanCanAtlas_miRNA_sample_information_list.txt', delimiter='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_metadata.rename(index=str, columns={'id': 'sample'}, inplace=True)\n",
    "sample_metadata.set_index('sample', inplace=True)\n",
    "sample_metadata.index = sample_metadata.index.map(lambda x: '-'.join(x.split('-')[0:4]))\n",
    "sample_metadata.reset_index(inplace=True)\n",
    "sample_metadata.drop_duplicates(subset='sample', keep='first', inplace=True)\n",
    "sample_metadata.set_index('sample', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merging mRNA and miRNA expression data and sample metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = sample_metadata.merge(sample_mRNAs, left_index=True, right_index=True)\n",
    "samples = samples.merge(sample_miRNAs, left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definitions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Considering samples of type 1 only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "type1_samples = pd.DataFrame(samples[samples.Sample_Type == 1])\n",
    "type1_sample_mirtars = type1_samples.drop(columns=sample_metadata.columns)\n",
    "type1_mirtar_data = type1_sample_mirtars.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "type1_sample_disease_mirtars = type1_samples.drop(columns=sample_metadata.columns).applymap(lambda x: m.log(x + 2, 2))\n",
    "type1_sample_disease_mirtars['Disease'] = type1_samples.Disease"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copying file://temp.csv [Content-Type=text/csv]...\n",
      "==> NOTE: You are uploading one or more large file(s), which would run          \n",
      "significantly faster if you enable parallel composite uploads. This\n",
      "feature can be enabled by editing the\n",
      "\"parallel_composite_upload_threshold\" value in your .boto\n",
      "configuration file. However, note that if you do this large files will\n",
      "be uploaded as `composite objects\n",
      "<https://cloud.google.com/storage/docs/composite-objects>`_,which\n",
      "means that any user who downloads such objects will need to have a\n",
      "compiled crcmod installed (see \"gsutil help crcmod\"). This is because\n",
      "without a compiled crcmod, computing checksums on composite objects is\n",
      "so slow that gsutil disables downloads of composite objects.\n",
      "\n",
      "\\ [1 files][  3.0 GiB/  3.0 GiB]   24.8 MiB/s                                   \n",
      "Operation completed over 1 objects/3.0 GiB.                                      \n"
     ]
    }
   ],
   "source": [
    "write_df_to_csv(type1_sample_disease_mirtars, 'sample', 'gs://yfl-mirna/data/miRTar/type1-sample_disease_miRNAmRNA-exprs.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Log transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "type1_sample_mirtars_log = type1_sample_mirtars.applymap(lambda x: m.log(x + 2, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Number of samples for each tumor type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "tumor_types_and_counts = type1_samples['Disease'].value_counts().sort_index()\n",
    "tumor_types = tumor_types_and_counts.index\n",
    "tumor_type_counts = tumor_types_and_counts.values\n",
    "tumor_types_num = tumor_types.size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Samples grouped by tumor type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_mirtars_groupedby_tumor_type = type1_samples.drop(columns=['Sample_Type', 'Protocol', 'Platform']).groupby('Disease')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "type1_sample_mirtars_log['Disease'] = type1_samples.Disease\n",
    "sample_mirtars_log_groupedby_tumor_type = type1_sample_mirtars_log.groupby('Disease')\n",
    "del type1_sample_mirtars_log['Disease']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variation in miRNAs and mRNAs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pearson and Spearman correlations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Across all samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "mRNA_na_counts = mRNA_data.isnull().sum(axis=1)\n",
    "mRNAs_nomissing = mRNA_na_counts[mRNA_na_counts == 0].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20531, 11069)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mRNA_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16335"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mRNAs_nomissing.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "mirtar_corrs_np = np.corrcoef(type1_sample_mirtars[sample_miRNAs.columns].values, type1_sample_mirtars[mRNAs_nomissing].values, rowvar=False)\n",
    "mirtar_corrs = pd.DataFrame(mirtar_corrs_np[:miRNAs_num, miRNAs_num:], sample_miRNAs.columns, mRNAs_nomissing)\n",
    "#log('miRTar corrs')\n",
    "#write_df_to_csv(mirtar_corrs, 'miRNA', 'gs://yfl-mirna/explore/miRTar/pearson-corrs/data/mirtar-corrs.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logged miRTar corrs\n",
      "Copying file://temp.csv [Content-Type=text/csv]...\n",
      "==> NOTE: You are uploading one or more large file(s), which would run          \n",
      "significantly faster if you enable parallel composite uploads. This\n",
      "feature can be enabled by editing the\n",
      "\"parallel_composite_upload_threshold\" value in your .boto\n",
      "configuration file. However, note that if you do this large files will\n",
      "be uploaded as `composite objects\n",
      "<https://cloud.google.com/storage/docs/composite-objects>`_,which\n",
      "means that any user who downloads such objects will need to have a\n",
      "compiled crcmod installed (see \"gsutil help crcmod\"). This is because\n",
      "without a compiled crcmod, computing checksums on composite objects is\n",
      "so slow that gsutil disables downloads of composite objects.\n",
      "\n",
      "/ [1 files][238.3 MiB/238.3 MiB]                                                \n",
      "Operation completed over 1 objects/238.3 MiB.                                    \n"
     ]
    }
   ],
   "source": [
    "mirtar_log_corrs_np = np.corrcoef(type1_sample_mirtars_log[sample_miRNAs.columns].values, type1_sample_mirtars_log[mRNAs_nomissing].values, rowvar=False)\n",
    "mirtar_log_corrs = pd.DataFrame(mirtar_log_corrs_np[:miRNAs_num, miRNAs_num:], sample_miRNAs.columns, mRNAs_nomissing)\n",
    "log('logged miRTar corrs')\n",
    "write_df_to_csv(mirtar_log_corrs, 'miRNA', 'gs://yfl-mirna/explore/miRTar/pearson-corrs/data/mirtar-log-corrs.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "type1_sample_mirtars_nomissing = type1_sample_mirtars[sample_miRNAs.columns].merge(type1_sample_mirtars[mRNAs_nomissing], left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "spearman_results = stats.spearmanr(type1_sample_mirtars_nomissing.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mirtar_spearman_corrs = pd.DataFrame(spearman_results.correlation[:miRNAs_num, miRNAs_num:], sample_miRNAs.columns, mRNAs_nomissing)\n",
    "mirtar_spearman_corr_pvals = pd.DataFrame(spearman_results.pvalue[:miRNAs_num, miRNAs_num:], sample_miRNAs.columns, mRNAs_nomissing)\n",
    "log('miRTar Spearman corrs')\n",
    "write_df_to_csv(mirtar_spearman_corrs, 'miRNA', 'gs://yfl-mirna/explore/miRTar/spearman-corrs/data/mirtar-spearman-corrs.csv')\n",
    "write_df_to_csv(mirtar_spearman_corr_pvals, 'miRNA', 'gs://yfl-mirna/explore/miRTar/spearman-corrs/data/mirtar-spearman-corr-pvals.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Within cancer types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "cancer_type_mRNA_data = type_samples[sample_mRNAs.columns].T\n",
    "mRNA_na_counts = cancer_type_mRNA_data.isnull().sum(axis=1)\n",
    "mRNAs_nomissing = mRNA_na_counts[mRNA_na_counts == 0].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for cancer_type, type_samples in sample_mirtars_groupedby_tumor_type:\n",
    "  cancer_type_mRNA_data = type_samples[sample_mRNAs.columns].T\n",
    "  mRNA_na_counts = cancer_type_mRNA_data.isnull().sum(axis=1)\n",
    "  mRNAs_nomissing = mRNA_na_counts[mRNA_na_counts == 0].index\n",
    "  # Pearson correlations\n",
    "  mirtar_corrs_np = np.corrcoef(type_samples[sample_miRNAs.columns].values, type_samples[mRNAs_nomissing].values, rowvar=False)\n",
    "  mirtar_corrs = pd.DataFrame(mirtar_corrs_np[:miRNAs_num, miRNAs_num:], sample_miRNAs.columns, mRNAs_nomissing)\n",
    "  log(cancer_type + ' miRTar corrs')\n",
    "  write_df_to_csv(mirtar_corrs, 'miRNA', 'gs://yfl-mirna/explore/miRTar/pearson-corrs/data/mirtar-corrs_' + cancer_type + '.csv')\n",
    "  # Spearman correlations\n",
    "  type1_sample_mirtars_nomissing = type_samples[sample_miRNAs.columns].merge(type_samples[mRNAs_nomissing], left_index=True, right_index=True)\n",
    "  spearman_results = stats.spearmanr(type1_sample_mirtars_nomissing.values)\n",
    "  mirtar_spearman_corrs = pd.DataFrame(spearman_results.correlation[:miRNAs_num, miRNAs_num:], sample_miRNAs.columns, mRNAs_nomissing)\n",
    "  mirtar_spearman_corr_pvals = pd.DataFrame(spearman_results.pvalue[:miRNAs_num, miRNAs_num:], sample_miRNAs.columns, mRNAs_nomissing)\n",
    "  log(cancer_type + ' miRTar Spearman corrs')\n",
    "  write_df_to_csv(mirtar_spearman_corrs, 'miRNA', 'gs://yfl-mirna/explore/miRTar/spearman-corrs/data/' + 'mirtar-spearman-corrs_' + cancer_type + '.csv')\n",
    "  write_df_to_csv(mirtar_spearman_corr_pvals, 'miRNA', 'gs://yfl-mirna/explore/miRTar/spearman-corrs/data/' + 'mirtar-spearman-corr-pvals_' + cancer_type + '.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Within cancer types for Pearson correlations of log-transformed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/envs/py3env/lib/python3.5/site-packages/numpy/lib/function_base.py:3183: RuntimeWarning: invalid value encountered in true_divide\n",
      "  c /= stddev[:, None]\n",
      "/usr/local/envs/py3env/lib/python3.5/site-packages/numpy/lib/function_base.py:3184: RuntimeWarning: invalid value encountered in true_divide\n",
      "  c /= stddev[None, :]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ACClogged miRTar corrs\n",
      "Copying file://temp.csv [Content-Type=text/csv]...\n",
      "==> NOTE: You are uploading one or more large file(s), which would run          \n",
      "significantly faster if you enable parallel composite uploads. This\n",
      "feature can be enabled by editing the\n",
      "\"parallel_composite_upload_threshold\" value in your .boto\n",
      "configuration file. However, note that if you do this large files will\n",
      "be uploaded as `composite objects\n",
      "<https://cloud.google.com/storage/docs/composite-objects>`_,which\n",
      "means that any user who downloads such objects will need to have a\n",
      "compiled crcmod installed (see \"gsutil help crcmod\"). This is because\n",
      "without a compiled crcmod, computing checksums on composite objects is\n",
      "so slow that gsutil disables downloads of composite objects.\n",
      "\n",
      "\\ [1 files][284.8 MiB/284.8 MiB]                                                \n",
      "Operation completed over 1 objects/284.8 MiB.                                    \n",
      "BLCAlogged miRTar corrs\n",
      "Copying file://temp.csv [Content-Type=text/csv]...\n",
      "==> NOTE: You are uploading one or more large file(s), which would run          \n",
      "significantly faster if you enable parallel composite uploads. This\n",
      "feature can be enabled by editing the\n",
      "\"parallel_composite_upload_threshold\" value in your .boto\n",
      "configuration file. However, note that if you do this large files will\n",
      "be uploaded as `composite objects\n",
      "<https://cloud.google.com/storage/docs/composite-objects>`_,which\n",
      "means that any user who downloads such objects will need to have a\n",
      "compiled crcmod installed (see \"gsutil help crcmod\"). This is because\n",
      "without a compiled crcmod, computing checksums on composite objects is\n",
      "so slow that gsutil disables downloads of composite objects.\n",
      "\n",
      "- [1 files][294.8 MiB/294.8 MiB]                                                \n",
      "Operation completed over 1 objects/294.8 MiB.                                    \n",
      "BRCAlogged miRTar corrs\n",
      "Copying file://temp.csv [Content-Type=text/csv]...\n",
      "==> NOTE: You are uploading one or more large file(s), which would run          \n",
      "significantly faster if you enable parallel composite uploads. This\n",
      "feature can be enabled by editing the\n",
      "\"parallel_composite_upload_threshold\" value in your .boto\n",
      "configuration file. However, note that if you do this large files will\n",
      "be uploaded as `composite objects\n",
      "<https://cloud.google.com/storage/docs/composite-objects>`_,which\n",
      "means that any user who downloads such objects will need to have a\n",
      "compiled crcmod installed (see \"gsutil help crcmod\"). This is because\n",
      "without a compiled crcmod, computing checksums on composite objects is\n",
      "so slow that gsutil disables downloads of composite objects.\n",
      "\n",
      "/ [1 files][295.9 MiB/295.9 MiB]                                                \n",
      "Operation completed over 1 objects/295.9 MiB.                                    \n",
      "CESClogged miRTar corrs\n",
      "Copying file://temp.csv [Content-Type=text/csv]...\n",
      "==> NOTE: You are uploading one or more large file(s), which would run          \n",
      "significantly faster if you enable parallel composite uploads. This\n",
      "feature can be enabled by editing the\n",
      "\"parallel_composite_upload_threshold\" value in your .boto\n",
      "configuration file. However, note that if you do this large files will\n",
      "be uploaded as `composite objects\n",
      "<https://cloud.google.com/storage/docs/composite-objects>`_,which\n",
      "means that any user who downloads such objects will need to have a\n",
      "compiled crcmod installed (see \"gsutil help crcmod\"). This is because\n",
      "without a compiled crcmod, computing checksums on composite objects is\n",
      "so slow that gsutil disables downloads of composite objects.\n",
      "\n",
      "/ [1 files][294.0 MiB/294.0 MiB]                                                \n",
      "Operation completed over 1 objects/294.0 MiB.                                    \n",
      "CHOLlogged miRTar corrs\n",
      "Copying file://temp.csv [Content-Type=text/csv]...\n",
      "==> NOTE: You are uploading one or more large file(s), which would run          \n",
      "significantly faster if you enable parallel composite uploads. This\n",
      "feature can be enabled by editing the\n",
      "\"parallel_composite_upload_threshold\" value in your .boto\n",
      "configuration file. However, note that if you do this large files will\n",
      "be uploaded as `composite objects\n",
      "<https://cloud.google.com/storage/docs/composite-objects>`_,which\n",
      "means that any user who downloads such objects will need to have a\n",
      "compiled crcmod installed (see \"gsutil help crcmod\"). This is because\n",
      "without a compiled crcmod, computing checksums on composite objects is\n",
      "so slow that gsutil disables downloads of composite objects.\n",
      "\n",
      "\\ [1 files][277.2 MiB/277.2 MiB]                                                \n",
      "Operation completed over 1 objects/277.2 MiB.                                    \n",
      "COADlogged miRTar corrs\n",
      "Copying file://temp.csv [Content-Type=text/csv]...\n",
      "==> NOTE: You are uploading one or more large file(s), which would run          \n",
      "significantly faster if you enable parallel composite uploads. This\n",
      "feature can be enabled by editing the\n",
      "\"parallel_composite_upload_threshold\" value in your .boto\n",
      "configuration file. However, note that if you do this large files will\n",
      "be uploaded as `composite objects\n",
      "<https://cloud.google.com/storage/docs/composite-objects>`_,which\n",
      "means that any user who downloads such objects will need to have a\n",
      "compiled crcmod installed (see \"gsutil help crcmod\"). This is because\n",
      "without a compiled crcmod, computing checksums on composite objects is\n",
      "so slow that gsutil disables downloads of composite objects.\n",
      "\n",
      "/ [1 files][255.6 MiB/255.6 MiB]                                                \n",
      "Operation completed over 1 objects/255.6 MiB.                                    \n",
      "DLBClogged miRTar corrs\n",
      "Copying file://temp.csv [Content-Type=text/csv]...\n",
      "==> NOTE: You are uploading one or more large file(s), which would run          \n",
      "significantly faster if you enable parallel composite uploads. This\n",
      "feature can be enabled by editing the\n",
      "\"parallel_composite_upload_threshold\" value in your .boto\n",
      "configuration file. However, note that if you do this large files will\n",
      "be uploaded as `composite objects\n",
      "<https://cloud.google.com/storage/docs/composite-objects>`_,which\n",
      "means that any user who downloads such objects will need to have a\n",
      "compiled crcmod installed (see \"gsutil help crcmod\"). This is because\n",
      "without a compiled crcmod, computing checksums on composite objects is\n",
      "so slow that gsutil disables downloads of composite objects.\n",
      "\n",
      "\\ [1 files][287.4 MiB/287.4 MiB]                                                \n",
      "Operation completed over 1 objects/287.4 MiB.                                    \n",
      "ESCAlogged miRTar corrs\n",
      "Copying file://temp.csv [Content-Type=text/csv]...\n",
      "==> NOTE: You are uploading one or more large file(s), which would run          \n",
      "significantly faster if you enable parallel composite uploads. This\n",
      "feature can be enabled by editing the\n",
      "\"parallel_composite_upload_threshold\" value in your .boto\n",
      "configuration file. However, note that if you do this large files will\n",
      "be uploaded as `composite objects\n",
      "<https://cloud.google.com/storage/docs/composite-objects>`_,which\n",
      "means that any user who downloads such objects will need to have a\n",
      "compiled crcmod installed (see \"gsutil help crcmod\"). This is because\n",
      "without a compiled crcmod, computing checksums on composite objects is\n",
      "so slow that gsutil disables downloads of composite objects.\n",
      "\n",
      "\\ [1 files][276.4 MiB/276.4 MiB]                                                \n",
      "Operation completed over 1 objects/276.4 MiB.                                    \n",
      "HNSClogged miRTar corrs\n",
      "Copying file://temp.csv [Content-Type=text/csv]...\n",
      "==> NOTE: You are uploading one or more large file(s), which would run          \n",
      "significantly faster if you enable parallel composite uploads. This\n",
      "feature can be enabled by editing the\n",
      "\"parallel_composite_upload_threshold\" value in your .boto\n",
      "configuration file. However, note that if you do this large files will\n",
      "be uploaded as `composite objects\n",
      "<https://cloud.google.com/storage/docs/composite-objects>`_,which\n",
      "means that any user who downloads such objects will need to have a\n",
      "compiled crcmod installed (see \"gsutil help crcmod\"). This is because\n",
      "without a compiled crcmod, computing checksums on composite objects is\n",
      "so slow that gsutil disables downloads of composite objects.\n",
      "\n",
      "\\ [1 files][293.9 MiB/293.9 MiB]                                                \n",
      "Operation completed over 1 objects/293.9 MiB.                                    \n",
      "KICHlogged miRTar corrs\n",
      "Copying file://temp.csv [Content-Type=text/csv]...\n",
      "==> NOTE: You are uploading one or more large file(s), which would run          \n",
      "significantly faster if you enable parallel composite uploads. This\n",
      "feature can be enabled by editing the\n",
      "\"parallel_composite_upload_threshold\" value in your .boto\n",
      "configuration file. However, note that if you do this large files will\n",
      "be uploaded as `composite objects\n",
      "<https://cloud.google.com/storage/docs/composite-objects>`_,which\n",
      "means that any user who downloads such objects will need to have a\n",
      "compiled crcmod installed (see \"gsutil help crcmod\"). This is because\n",
      "without a compiled crcmod, computing checksums on composite objects is\n",
      "so slow that gsutil disables downloads of composite objects.\n",
      "\n",
      "| [1 files][281.8 MiB/281.8 MiB]                                                \n",
      "Operation completed over 1 objects/281.8 MiB.                                    \n",
      "KIRClogged miRTar corrs\n",
      "Copying file://temp.csv [Content-Type=text/csv]...\n",
      "==> NOTE: You are uploading one or more large file(s), which would run          \n",
      "significantly faster if you enable parallel composite uploads. This\n",
      "feature can be enabled by editing the\n",
      "\"parallel_composite_upload_threshold\" value in your .boto\n",
      "configuration file. However, note that if you do this large files will\n",
      "be uploaded as `composite objects\n",
      "<https://cloud.google.com/storage/docs/composite-objects>`_,which\n",
      "means that any user who downloads such objects will need to have a\n",
      "compiled crcmod installed (see \"gsutil help crcmod\"). This is because\n",
      "without a compiled crcmod, computing checksums on composite objects is\n",
      "so slow that gsutil disables downloads of composite objects.\n",
      "\n",
      "| [1 files][293.2 MiB/293.2 MiB]                                                \n",
      "Operation completed over 1 objects/293.2 MiB.                                    \n",
      "KIRPlogged miRTar corrs\n",
      "Copying file://temp.csv [Content-Type=text/csv]...\n",
      "==> NOTE: You are uploading one or more large file(s), which would run          \n",
      "significantly faster if you enable parallel composite uploads. This\n",
      "feature can be enabled by editing the\n",
      "\"parallel_composite_upload_threshold\" value in your .boto\n",
      "configuration file. However, note that if you do this large files will\n",
      "be uploaded as `composite objects\n",
      "<https://cloud.google.com/storage/docs/composite-objects>`_,which\n",
      "means that any user who downloads such objects will need to have a\n",
      "compiled crcmod installed (see \"gsutil help crcmod\"). This is because\n",
      "without a compiled crcmod, computing checksums on composite objects is\n",
      "so slow that gsutil disables downloads of composite objects.\n",
      "\n",
      "| [1 files][293.0 MiB/293.0 MiB]                                                \n",
      "Operation completed over 1 objects/293.0 MiB.                                    \n",
      "LGGlogged miRTar corrs\n",
      "Copying file://temp.csv [Content-Type=text/csv]...\n",
      "==> NOTE: You are uploading one or more large file(s), which would run          \n",
      "significantly faster if you enable parallel composite uploads. This\n",
      "feature can be enabled by editing the\n",
      "\"parallel_composite_upload_threshold\" value in your .boto\n",
      "configuration file. However, note that if you do this large files will\n",
      "be uploaded as `composite objects\n",
      "<https://cloud.google.com/storage/docs/composite-objects>`_,which\n",
      "means that any user who downloads such objects will need to have a\n",
      "compiled crcmod installed (see \"gsutil help crcmod\"). This is because\n",
      "without a compiled crcmod, computing checksums on composite objects is\n",
      "so slow that gsutil disables downloads of composite objects.\n",
      "\n",
      "\\ [1 files][293.8 MiB/293.8 MiB]                                                \n",
      "Operation completed over 1 objects/293.8 MiB.                                    \n",
      "LIHClogged miRTar corrs\n",
      "Copying file://temp.csv [Content-Type=text/csv]...\n",
      "==> NOTE: You are uploading one or more large file(s), which would run          \n",
      "significantly faster if you enable parallel composite uploads. This\n",
      "feature can be enabled by editing the\n",
      "\"parallel_composite_upload_threshold\" value in your .boto\n",
      "configuration file. However, note that if you do this large files will\n",
      "be uploaded as `composite objects\n",
      "<https://cloud.google.com/storage/docs/composite-objects>`_,which\n",
      "means that any user who downloads such objects will need to have a\n",
      "compiled crcmod installed (see \"gsutil help crcmod\"). This is because\n",
      "without a compiled crcmod, computing checksums on composite objects is\n",
      "so slow that gsutil disables downloads of composite objects.\n",
      "\n",
      "\\ [1 files][293.8 MiB/293.8 MiB]                                                \n",
      "Operation completed over 1 objects/293.8 MiB.                                    \n"
     ]
    }
   ],
   "source": [
    "for cancer_type, type_samples in sample_mirtars_log_groupedby_tumor_type:\n",
    "  cancer_type_mRNA_data = type_samples[sample_mRNAs.columns].T\n",
    "  mRNA_na_counts = cancer_type_mRNA_data.isnull().sum(axis=1)\n",
    "  mRNAs_nomissing = mRNA_na_counts[mRNA_na_counts == 0].index\n",
    "  mirtar_log_corrs_np = np.corrcoef(type_samples[sample_miRNAs.columns].values, type_samples[mRNAs_nomissing].values, rowvar=False)\n",
    "  mirtar_log_corrs = pd.DataFrame(mirtar_log_corrs_np[:miRNAs_num, miRNAs_num:], sample_miRNAs.columns, mRNAs_nomissing)\n",
    "  log(cancer_type + 'logged miRTar corrs')\n",
    "  write_df_to_csv(mirtar_log_corrs, 'miRNA', 'gs://yfl-mirna/explore/miRTar/pearson-corrs/data/mirtar-log-corrs_' + cancer_type + '.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Appendix for possible future use"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Drop mRNAs not in both dataset and miRTarBase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "mRNA_mirtar_data_intersection = set(mirtarbase_target_entrezID_to_IDs.keys()).intersection(set(mRNA_entrezIDs.tolist()))\n",
    "mirtar_data = mirtar_data[mirtar_data.target_entrezID.isin(mRNA_mirtar_data_intersection)]\n",
    "mRNA_data = mRNA_data[mRNA_data.entrezID.isin(mRNA_mirtar_data_intersection)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Drop miRNAs not in both dataset and miRTarBase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "miRNA_mirtar_data_intersection = mirtar_data.index.unique().intersection(miRNA_data.index.unique()).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "738"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(miRNA_mirtar_data_intersection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mirtar_data = mirtar_data[mirtar_data.index.isin(miRNA_mirtar_data_intersection)]\n",
    "miRNA_data = miRNA_data[miRNA_data.index.isin(miRNA_mirtar_data_intersection)]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
